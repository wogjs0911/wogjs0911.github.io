---
key: /2024/01/15/KafkaStudy1.html
title: Kafka - Kafka Study1
tags: eventbroker messagebroker redis kafka
--- 

# 1. `Message Broker` vs `Event Broker`

### 1) Message Broker

- `메시지 브로커`는 일반적으로 대기업들에서 대규모 메시지 기반 미들웨어 아키텍쳐에서 사용되어 왔다. `미들웨어`는 서비스하는 애플리케이션들을 보다 효율적으로 아키텍처들을 연결하는 요소들로 작동하는 소프트웨어이다.

<br>
- 예를 들어, 메시징 플랫폼, 인증 플랫폼, 데이터베이스 등이 있다.

<br>
- 또한, `메시지 브로커`는 메시지 브로커에 있는 큐에 데이터를 보내고 받는 `프로듀서`와 `컨슈머`를 통해 메시지를 통신하고 네트워크를 맺는 용도로 사용해왔다.

<br>
- `메시지 브로커`는 메시지를 받아서 적절히 처리하고나서 `즉시` 또는 `짧은 시간 내`에 `삭제되는 구조`이다.

---

<br><br>

### 2) Event Broker

- `이벤트 브로커`는 '메시지 브로커'의 구조와 다른 구조로 만들어져 있다.

<br>
- a. 이벤트 또는 메시지라고도 불리는 `레코드`인 이 장부를 딱 하나만 보관하고 `인덱스`를 통해 `개별 액세스`를 관리한다. 

<br>
- b. 업무상 필요한 시간 동안, 이벤트를 보존할 수 있다. 이것이 메시지 브로커와 가장 큰 차이점이다.

---

<br><br>

### 3) 최종 정리

- `메시지 브로커`는 데이터를 보내고, 처리하고 삭제한다. 하지만, 이벤트 브로커는 데이터를 삭제하지 않는다.

<br>
- `이벤트 브로커`가 데이터를 삭제하지 않는 이유? 
	- `이벤트 브로커`에서 '이벤트'라는 의미 때문이다. 이벤트 브로커는 서비스에서 나오는 이벤트를 마치 데이터베이스에 저장하듯이 이벤트 브로커의 큐에 저장한다.
	- 이렇게 저장함으로써 얻는 명확한 이점이 있다. 
	
	
---


<br><br>

### 4) 이벤트 브로커 이점

- 첫번째 이점은 딱 한번 일어난 이벤트 데이터를 브로커에 저장함으로서 단일 진실 공급원으로 상요할 수 있다. 

<br>
- 두번째는 장애가 발생했을 때, 장애가 일어난 지점부터 재처리할 수 있다. 

<br>
- 세번째는 많은 양의 실시간 스트림 데이터를 효과적으로 처리할 수 있다는 특징이 있다. 그외에는 MSA에서 중요한 역할을 맡을 수 있다.

<br>
- 종류** : 메시지 브로커는 보통 `Redis`, `RabbitMQ`를 이용한다. 이벤트 브로커는 `카프카`나 AWS의 `키네시스`가 대표적이다.


---

<br><br>


# 2. Kafka

### 1) 카프카 구조

- 먼저, 카프카는 프로듀서, 카프카, 컨슈머, 주키퍼 이렇게 총 네 가지로 분리를 할 수가 있다.

<br>
- 이 프로듀서는 카프카로 메시지를 보내는 역할을 한다. 그리고 그 카프카는 프로듀서가 보낸 메시지를 저장하는 역할을 한다.

<br>
- 컨슈머는 카프카에 저장되어 있는 메시지를 가져오는 역할을 한다. 그리고 그 카프카는 프로듀서가 보낸 메시지를 저장하는 역할을 한다.

<br>
- 그리고 이 카프카는 분산 코디네이터 시스템인 주키퍼와 연결을 하면서 메타데이터 관리라든지 아니면 클러스터의 노드 관리라든지 이런 것들을 주키퍼를 통해서 하고 있다.

---

<br><br>

### 2) 카프카 설치 스펙

- 그래서, 만약에 카프카 클러스터를 처음 구성하신다고 하시면 주키퍼 같은 경우에는 리플리케이션 방식, 커런 방식이기 때문에 홀수를 유지시켜줘야 된다.

<br>
- 그래서, 최소 수량인 3대로 구성하는 것입니다 3대로 구성을 해줘야 된다. 그리고, 카프카 같은 경우에는 리플리케이션 방식이 커런 방식이 아니다.

<br>
- 그래서 홀수든 짝수든 전혀 상관이 없지만 리플리케이션 팩터를 최소 3으로 유지를 하는 경우가 많기 때문에 최소 브로커 수를, 카프카 수를 3대로 하시는 게 좋다.

<br>
- 그래서, 총 최소 6대의 서버가 필요하게 된다. 이 카프카 같은 경우에는 만약에 사용량이 몰려서 서버를 증설하거나 이런 경우가 발생을 하면 주키퍼 같은 경우에는 3대로 구성을 해줘야 된다.

<br>
- 그래서 총 최소 6대의 서버가 필요하게 된다. 주키퍼는 그대로 내버려 둔 채 카프카만 서버를 추가해서 이렇게 스케일아웃하는 형식으로 5대, 10대 이런 식으로 스케일아웃 할 수가 있다.

<br>
- 카카오에서는 전사 공용 카프카를 운영을 하고 있다. 처음에 오픈했을 때 당시에는 2개의 클러스터로 약 서버는 10대 정도로 시작을 했었다. 

<br>
- 그런데 지금 오늘날에 이르러서는 7개의 클러스터로 약 130여 대 정도의 서버를 운영하고 있다. 그리고 이 130여 대의 서버는 카카오에서 IDC를 여러 군데를 사용하고 있다.

<br>
- 메인으로 사용하고 있는 IDC 두 곳에 집중을 해서 각 IDC마다 주키퍼 세트를 하나씩 두고 있다. 그 주키퍼 세트와 카프카 클러스터를 연결해서 총 7개의 클러스터를 운영을 하고 있다.

<br>
- 그리고 이 서비스들은 카카오에서 많은 분들이 알고 있는 다음 거래가 될 수 있는 서비스이다.

<br>
- 이런 서비스들이 공용 카프카 클러스터 130여 대의 클러스터를 거의 모두 이용하고 있다고 보시면 된다. 그래서 이러한 카카오 서비스들이 하루에 이 카프카를 통해서 처리하고 있는 메시지 건수는
약 한 2600억 개의 메시지를 하루에 처리하고 있다.

<br>
- 이게 이 카프카를 통해서 처리하고 있는 메시지 건수는 초당 한 300만 건의 메시지를 쉬지 않고 계속 처리하고 있다고 보시면 된다. 그리고 카프카로 들어오는 데이터 사이즈를 보게 되면 하루에 240테라바이트 정도의 데이터가 카프카를 통해서 데이터가 들어오게 된다.

<br>
- 그리고 반대로 하루에 370테라바이트 정도의 사이즈가 하루에 370테라바이트 정도의 데이터가 들어오게 되고요 카프카를 통해서 바깥으로 나가게 된다. 카프카 같은 경우에는 하나의 토픽을 기준으로 프로듀서가 메시지를 보내고 여러 컨슈머들이 붙어서 가져가는 구조가 일반적인데 이렇게 인보다 아웃이 1.3배, 4배, 5배 많은 수치를 보면 카프카를 잘 활용하고 있다는 것을 알 수가 있다.

<br>
- 그리고 제가 자료를 만들기 위해서 가동률이라는 것을 한번 계산을 하면 카프카를 운영한 지는 한 2년 정도 운영을 하게 되었는데 크게 클러스터 전체가 이슈가 생겼던 것은 두 건 정도가 있었다. 그래서, 그거를 약간 시간을 따져보니까 한 시간이 채 되지 않았지만 대략적인 시간으로 계산을 해봤을 때 가동률이 약 99.99% 정도 나왔다.

<br>
- 사실, 이렇게 99.99%가 나온 것은 거의 잠들지 않은 서비스이다. 그래서 이 정도만으로도 이 정도만으로도 기술이 가능한 서비스를 하고 있었다고 볼 수가 있을 것 같다.

---

<br><br>

### 3) 카프카 사용기 이슈

#### a. Shrinking ISR

##### a) ISR

- `ISR`은 `In-Sync Replica`라는 첫 글자를 따서 ISR이라고 부르게 된다.

<br>
- ISR이 다른 어플리케이션에서 많이 쓰이는 용어는 아니다.

<br>
- 카프카에서 특화돼서 사용하는 용어 중의 하나이다. 그리고, 이게 리플리케이션이 되어 있고 똑같은 구성원이 있기 때문에 이 구성원을 분류를 해줘야 된다.

---

<br>

##### b) 리플리케이션 : 리더, 팔로워

- 카프카에서는 이 리플리케이션 분류를 위해서 리더와 팔로워로 분류를 하고 있다. 이렇게, 분류된 만큼 각각의 역할이 다르게 된다.

<br>
- 그래서, 리더는 읽고 쓰기를 주로 하고 있고 그리고 팔로워들은 그 리더랑 주기적으로 동기화하는 작업을 하게 된다.

<br>
- 그리고 ISR이 생겨난 이유 자체가 이게 가장 중요한 이유인데 ISR의 구성원만이 리더의 자격을 가질 수 있기 때문이다.

<br>
- 이렇게 카프카 클러스터가 있다고 가정을 하고 거기에 브로커 3대가 있다고 가정을 하자. 

<br>
- 그리고 리플리케이션 팩터는 '3'이라고 가정을 하면, 이 카프카에는 토픽이 3개가 있다. 

<br>
- 그리고 이 토픽은 파티션이라는 단위로 쪼개질 수가 있다. 그래서 1개서부터 10개, 20개, 20개 이런 식으로 쪼개질 수가 있는데 여기서는 예제를 위해서 파티션 하나로만 표시하면, 파티션 1은 여기 보시는 것처럼 0번부터 시작하게 된다. 그래서 이거는 토픽 하나에 파티션 하나를 나타내고 있는 것이다. 그리고 리더와 팔로우가 있기 때문에 리더는 별도로 표시했다.

<br>
- 그리고 이 리더와 팔로우들을 이렇게 그룹핑하고 있는 이것이 바로 ISR이라고 하는 것입니다. 그래서 브로커 1번이 예를 들어서 장애가 발생을 하게 되면 리더에 문제가 생긴 것이다.

<br>
- 그렇게 되면 이런 식으로 팔로우 중에 하나가 새로운 리더로 넘어가게 된다.

<br>
- 그리고 ISR이 축소가 되었다. 이렇게 ISR이 축소되는 것을 카프카에서는 `Shrinking ISR`이라고 한다.

---

<br>

##### c) 실무 : 이상 감지 예시

- 실무* : 실무에서 카프카를 운영하고 있었는데 어느 날 갑자기 브로커 서버에 문제가 있냐 아니면 이런 식의 문의가 왔었다. 이벤트로 메시지를 보내는데 메시지가 잘 안 간다 아니면 메시지를 가져오는데 잘 못 받는다 등의 이런 식으로 문의가 왔었다.

<br>
- 그래서 한 번 서버 전체적으로 상태를 봤는데 알람은 전혀 안 왔기 때문에 서버 전체적으로 봤는데 서버 다운된 것도 하나도 없이 모두 잘 동작을 하고 있었다.

<br>
- 그런데 보통 그래프, 그래프 하나를 이용해서 이렇게 그래프를 보는데 '인'이랑 '아웃' 쪽에 데이터가 그래프가 약간 좀 이상한 현상이 보이기 시작했다.

<br>
- 그래서 뭔가 이상을 감지하고 브로커 서버에 전체 로그인을 해서 로그를 보기 시작했지만 여기서 보시면 여기 로그 레벨이 INFO라고 찍혀 있는 부분을 보면 다음에도 주의해야 한다.

<br>
- 카프카에서는 로그 레벨이 총 3단계로 나눠져 있다. INFO, WARNING, ERROR 이렇게 나눠져 있는데 INFO는 정말 말 그대로 INFO 레벨이다. INFO성 로그다. WARNING은 경고성 그리고 ERROR는 정말 카프카에 문제가 생겼을 때 발생한 로그다.

<br>
- 처음에는 이 INFO성 로그는 제외하고 WARNING 또는 ERROR 메세지가 브로커 로그에 한 줄 기록되자마자 바로 알림을 받을 수 있도록 알람 설정을 해 놨었는데 지금 보시는 것처럼 INFO성 로그였기 때문에 알람을 미리 받지 못했다.

<br>
- 그리고 이 문제성 로그를 보면, 여기 브로커 5번에서 쉬링킹 ISR이 발생을 했고 이 토픽에 대해서 이렇게 축소되는 이런 이슈가 발생을 했던 것이다. 그래서, 이거를 약간 시각화해서 보면은 클러스터 내에 브로커들이 여러 대가 있었는데 브로커 5번이 오동작으로 인해서 모든 ISR 자기가 가지고 있던 파티션에 대해서 모든 ISR을 축소하는 현상이 발생했다.

<br>
- 그리고 이 브로커 5번이 모든 ISR을 축소하는 현상이 발생했다. 이 브로커 5번이 자기가 가지고 있던 파티션에 대해서 리더를 다 가져가 버렸기 때문에 다른 브로커들은 이 브로커 5번과 리플리케이션을 해야 되는데 이 리플리케이션이 안 되는 이런 에러가 발생을 하고 있었 것이다.

<br>
- 그래서 이 증상은 그 당시에 사용하고 있었던 0.10.1.0의 버그였다. 그리고 이 내용을 확인했을 때 이미 상위 버전이 릴리즈되어서 이 버그에 대해서는 픽스가 되었던 상황이었다.

<br>
- 그래서, 이 버그에 대해서는 픽스가 되었던 상황이었다.

<br>
- 여기서 한 가지 말하고 싶은 것은 브로커에서 로그가 WARNING 또는 ERROR 로그만 이렇게 감지를 한다고 하더라도 이렇게 INFO 로그가 왜 발생했는지에 대해서 조금 더 한번 고민을 해 보시면 나중에 이슈가 생기더라도 트러블 슈팅하는데 도움될 것입니다.

---

<br>

##### d) 카프카 : 버전 업그레이드 방식

- 그래서, 저희는 결국에 이 버전을 버리고 상위 버전으로 업그레이드를 해야 되는데 이 카프카에서 버전 업그레이드를 하는 방식은 두 가지가 있다.

<br><br>

##### A. 첫 번째 방식 : 다운타임 유무

- 첫 번째로는 다운타임을 가질 수 있는 환경이랑 그리고 다운타임을 가질 수 없는 환경 이렇게 크게 두 가지로 나눌 수가 있는데 다운타임을 가질 수 있는 환경은 정말 심플하게 작업을 할 수가 있다.

<br>
- 모든 브로커를 다 내려버리고 최신 버전으로 업그레이드 한 다음에 브로커를 그냥 실행해 주면 업그레이드가 끝나게 된다.

<br>
- 하지만, 아마 일반적인 보통의 상황들이 다운타임을 가질 수 없는 환경일 것이다. 이런 상황에서는 클러스터 내 브로커를 한 대씩 내렸다가 버전 업그레이드하고 올리고 내렸다가 버전 업그레이드하고 올리고 이런 식으로 작업을 진행해야 한다.

<br>
- 그래서, 전체 클러스터는 다운되지 않은 상태에서 한 대씩 한 대씩 버전 업그레이드를 진행해야 된다.

<br>
- 그래서, 카카오에서는 크리티컬한 이슈가 방금 아까 그런 버그같은 이런 일들이 발생을 하거나 아니면 카프카의 새로운 신규 기능이 추가되어서 그 기능을 써야만 하는 경우, 그럴 때를 다운타임 없이 버전 업그레이드를 진행을 하고 있다.


---

<br><br>

#### b. 전원 이슈

- 그리고 두 번째 이슈는 전원 이슈였다. 일반적으로 서버들을 IDC에 두게 된다.

<br>
- 그리고 그 IDC에는 랙이라고 불리우는 공간에다가 서버를 두게 되는데 랙은 뭐 이런 선반 같은 개념이다.

<br>
- 좀 더 자세히 보면 이런 식으로 이렇게 랙 1, 2, 3이 있다. 그리고, 이 랙 1, 2, 3에다가 이제 원하는 서버들을 자유롭게 꽂게 된다.

<br>
- 브로커 서버, DB 서버, 웹 서버 뭐 이런 식으로 랙에다가 서버를 꽂게 됩니다. 근데 카프카 같은 경우에는 이제 클러스터 개념이기 때문에 3대가 있다고 가정을 해보고 그 브로커 1, 2, 3을 랙 1번에다가만 몰아놨다고 가정하자.

<br>
- 사실 이렇게 구성을 하게 되면은 랙 1번이 문제가 생기게 되면 클러스터 전체가 다운되는 문제가 생기게 된다.

<br>
- 그렇기 때문에 각 랙마다 브로커 서버를 분산해서 한 대씩 한 대씩 배치하는 것이 효율적인 배치이다.

<br>
- 근데 그 랙 전원장애가 발생을 했다고 말씀을 드렸는데 IDC의 랙 전원장애가 발생했을 때 랙 한 열이, 그러니까 약 한 15개 정도의 렉의 전원이 한 번에 다다다닥 전원이 나간 상황이다.

<br>
- 그러니까, 랙 15개 내에 클러스터가 한 10개 이렇게 구성이 되어 있었는데 거기에 랙 전원이 전부 다 나가면서 모든 브로커가 다운되는 상황을 겪게 된 것이다.

<br>
- 그래서 이렇게 모든 브로커가 다운되는 경우가 흔하진 않지만 이런 경우에 대해서도 한 번쯤은 고민을 해야 한다.


---

<br>

##### a) 다운타임이 없는 경우의 전원 이슈 해결 예시

<br>
- 예를 들어, 이렇게 랙 1, 2, 3이 있고 거기에 브로커 1, 2, 3이 있다고 가정을 해보자.

<br>
- 그리고 거기에 'peter-topic'이라는 게 있고 메시지 'a'를 가지고 있다고 가정을 해보자. 그리고 노란색은 리더고 팔로워 두 개가 있다고 가정을 하자.

<br>
- 그런데 여기서 랙 1번에 전원장애가 발생을 한 것이다. 이렇게 전원장애가 발생을 하게 되면 팔로워에게 새로운 리더가 넘어가게 되고 다음 메시지인 'b'라는 메시지를 받게 된다.

<br>
- 그리고 렉 2번도 전원장애가 발생을 했고 다음 리더인 마지막 브로커로 리더가 넘어가게 된다. 그리고 마지막 브로커는 다음 메시지인 'c'라는 메시지를 받게 된다.

<br>
- 그런데 하나 남은 브로커도 역시 전원장애를 피해갈 수는 없다.

<br>
- 렉 3번에 전원장애가 발생을 하게 됩니다. 그럼 전원장애가 발생한 이후에 렉 3번이 가장 먼저 복구가 되게 되면 마지막 리더가 그냥 바로 새로운 리더가 되는 거죠.

<br>
- 계속 이어지는 리더가 되는 거죠. 그러고 나서 다음 메시지인 'd'라는 메시지를 받게 되고 나머지 장애에 빠져 있었던 브로커 2번과 1번이 복구가 됐을 때, 렉 3번이 전원장애가 발생을 하게 된다.

<br>
- 이미 리더가 있기 때문에 그 리더로부터 모든 메시지를 동기화하게 된다. 결국에는 전원장애로 인해서 모든 브로커가 다운됐음에도 불구하고 메시지 손실은 하나도 없게 되는 현상이 있다. 하지만 가장 먼저 다운됐었던 브로커 1번이 가장 먼저 복구가 됐다고 가정을 해보자.

<br>
- 그리고 이 브로커 1번이 바로 리더가 아무도 없기 때문에 즉시 리더의 역할을 하게 됩니다. 그러고 나서 메시지 d를 받게 되는 거죠. 다음에 랙 2번과 3번의 문제가 해결돼서 브로커가 올라왔을 때 이미 브로커 1번이 리더 역할을 하고 있기 때문에 모든 메시지를 리플리케이션 하게 됩니다. 결국 메시지 'b'와 'c'는 손실되게 되는 겁니다.


---

<br>

##### b) 결론


<br>
- 사실 여기에서는 서비스의 영속성을 우선시 할 건지 아니면 데이터의 정합성을 우선시 할 건지 선택의 문제지 정답이 있는 것은 아닙니다.

<br>
- 근데 마지막 리더를 기다리는 옵션으로 설정을 해서 사용할 경우에 이렇게 모든 클러스터가 다운됐음에도 불구하고 메시지 손실을 없게 할 수가 있다.

<br>
- 하지만 우리는 최악의 시나리오도 고려를 해야 됩니다. 만약에 마지막 리더였던 서버가 전원장애 이후에 올라오지 않는 상황도 고려를 해야 되는 거죠.

<br>
- 뭔가 메인보드가 문제가 있다든지 아니면 뭔가 파워 서플라이가 문제가 있다든지 그래서 만약에 올라오지 않게 되면 다른 팔로우들은 이미 올라와 있는데도 마지막 리더가 올라오지 않기 때문에 장애 시간이 계속해서 길어질 수가 있다.

<br>
- 카카오에서는 전사 공용으로 사용하고 있기 때문에 장애가 발생을 했을 때, 최대한 장애 타임을 줄이고 빠르게 서비스에 투입되는 것이 최우선이었다.

<br>
- 그래서 이런 렉 전원장애가 발생을 했을 때, 서비스의 영속성을 우선시 했기 때문에 일부 메시지는 손실이 되었고 대신에 빠른 서비스 투입이 가능했었다.

<br>
- 그래서, 이런 사항을 잘 고려하셔서 용도에 맞게 카푸카를 운영하시면 사용하시는데 도움이 될 것 같다.

---