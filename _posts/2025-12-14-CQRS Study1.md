---
key: /2025/12/14/CQRSStudy1.html
title: CQRS - CQRS Study 1
tags: CQRS Event-Driven-Architecture Kafka CDC Debezium Elasticsearch MongoDB Zookeeper
---

# CQRS 방법론 정리 (2024.05 ~ 2024.12)

## 목차
1. [CQRS 개념 정리](#1-cqrs-개념-정리)
2. [실생활 적용 시스템 아키텍처](#2-실생활-적용-시스템-아키텍처)
3. [이벤트 기반 아키텍처](#3-이벤트-기반-아키텍처)
4. [Kafka 개념 및 실습](#4-kafka-개념-및-실습)
5. [Debezium 프로젝트 실습](#5-debezium-프로젝트-실습)
6. [다중 데이터 저장소 전략](#6-다중-데이터-저장소-전략)
7. [실습 코드 분석](#7-실습-코드-분석)
8. [실습 환경 구성](#8-실습-환경-구성)
9. [Kafka 개발 환경 이슈 해결](#9-kafka-개발-환경-이슈-해결)
10. [JPA 실무 가이드](#10-jpa-실무-가이드)
11. [종합 정리](#11-종합-정리)

---

## 1. CQRS 개념 정리

### 1.1 CQRS 들어가기 전에

**중간 테이블의 이점**
- 주문 시 상품 정보를 중복 작성할 필요 없음
- 중간 테이블만 업데이트하면 됨
- 상품 정보 변경 시 전체 업데이트 불필요

**인덱스 사용 범용성**
- RDBMS의 B-Tree 기반 인덱스
- Embedded Index
- 검색 엔진에서의 인덱스
- RDBMS 벡터 검색: 벡터 데이터 형변환 시 무거운 벡터 오퍼레이션을 CQRS로 적용

<br>

### 1.2 이벤트 드리븐 방식: 인과적 일관성

**연쇄적 상태 변경**
- 하나의 트랜잭션이 아닌 경우 상태 업데이트 과정을 느슨하게 분리
- ⚠️ 주의: 주문 수량 변경은 이벤트로 개발하면 안 됨
- ✅ 가능: 결제 상태 변경은 이벤트 드리븐 방식 적용 가능

<br>

### 1.3 CQRS의 기술 이점

**장점**
- DB를 목적에 맞게 분리하여 성능 최적화 가능
- 읽기 부하 감소: 100의 쿼리 부하 → 90으로 감소 가능
- 주로 읽기가 많은 경우에 효과적

**단점 및 Trade-Off**
- DB 사용 분리로 인한 코드 복잡성 증가
- Command 데이터 모델 변경 시 Query 데이터 모델도 함께 변경 필요
- 커맨드에서의 부하보다 쿼리의 부하가 압도적으로 높음


<br>


### 1.4 CQRS 구현 단계

**1단계: 코드 수준 분리**
- 메서드로 Query와 Command 분리

**2단계: 모델 분리**
- 같은 DB 내에서 역할에 맞는 모델 분리
- 상품정보, 가격, 카테고리 등을 모은 통합 모델 생성

**3단계: 저장소 수준 분리 (CQS)**
- 비즈니스 모델의 특성에 따라 DB 선택
- DB까지 분리해야 최종적인 CQRS 완성


<br>


### 1.5 동기화 방식

**비동기식 업데이트**
- 커맨드 모델 변경 → 이벤트 큐 → 쿼리 모델 업데이트
- 네트워크 문제로 인한 최종 일관성 보장 복잡
- 지연 시간 발생 가능

**동기식 업데이트**
- 즉시 반영
- 성능 저하 가능성


<br>

### 1.6 일관성 전략

**강한 일관성**
- 결제, 예약 시스템, 재고 시스템에 적용
- 성능적으로 불리하나 중요한 비즈니스에 필수

**인과적 일관성**
- 게시글 작성 시 작성자에게는 즉시 표시
- 다른 사용자에게는 지연 허용

**최종 일관성**
- 상품 등록 후 몇백ms 후 목록 반영
- 성능적으로 유리


<br>

### 1.7 추가 참고사항

**응답 시간 기준**
- 현업에서는 일반적으로 100~200ms 정도로 응답 시간 측정

**관계 구조**
- 주문-상품 관계에서 주문이 메인이므로 주문 입장에서는 1:N 구조

<br><br>

---

## 2. 실생활 적용 시스템 아키텍처

### 2.1 소셜 미디어 피드 시스템

#### 온디맨드 조회 방식의 문제점

**성능 문제**
- 대량 JOIN 연산
- N+1 문제 발생
- 네트워크 라운드 트립 증가로 인한 성능 하락
- 카디널리티 익스플로젼: 수천 명 팔로우 시 JOIN 연산 비용 급증

**사용자 경험 저하**
- 느린 피드 로딩 시간
- 사용자 기반 확대 시 DB 성능 문제 심화

<br>

#### 해결 방안: 미리 계산된 피드

**Kafka를 통한 이벤트 전파**
- 상태 변경 이벤트 전파
- 미리 계산된 피드에서 쿼리 모델 사용


<br>

**Fan-Out 전략 최적화**

| 전략 | 대상 | 저장소 | 특징 |
|------|------|--------|------|
| Fan-out-on-Write | 일반 사용자 | RDBMS | 팔로워가 적은 경우, 게시글 즉시 배포(저장) |
| Fan-out-on-Read | 인플루언서 | NoSQL | 팔로워가 많은 경우, 게시글을 요청 시 병합 (Hotspot 레코드) |

<br>

**최종 피드 생성**
- 두 조회 결과를 병합하여 사용자 피드에 표시


<br>

#### NoSQL 최적화 기법

**키 설계**
- 파티션 키
- 클러스터링 키: 시간순 정렬 저장으로 범위 쿼리 최적화
- 복합 프라이머리 키로 페이지네이션 효율화

**데이터 모델링**
- 비정규화로 조인 없이 조회 가능

<br>

#### 아키텍처 구성

**동기화 방식**
- 비동기 Kafka를 이용한 동기화

<br><br>

### 2.2 커머스 플랫폼의 상품 관리/검색 시스템

#### 핵심 개념

**모델 동기화 컴포넌트**
- Elasticsearch 활용

<br>

**멱등성**
- 몇 번을 조회하더라도 일관성 제공 및 보장

<br>

**이벤트 발행**
- Kafka에 이벤트 발행
- CDC(Change Data Capture) 개념 이용
- Debezium 커넥터 활용

<br><br>

#### 검색 모델 구성

**반정규화 모델**
- 정규화된 테이블들을 반정규화된 모델로 구성
- 하나의 통합 문서로 검색 및 필터링 수행

**멀티필드 인덱스**
- 복합 필드 필터링을 통한 빠른 결과 도출
- 역색인(Inverted Index) 활용

<br><br>

#### 검색 인덱스 업데이트

**데이터 인덱싱**
- 변환된 데이터를 Elasticsearch에 인덱싱(저장)
- 벌크 연산으로 성능 최적화
- 네트워크 라운드 트립 감소
- Kafka Consumer에서 특정 양을 한 번에 가져와 효율적으로 업데이트

<br><br>

#### 커머스 플랫폼 CQRS 아키텍처

**커맨드 모델**
```
PostgreSQL → WAL 로그 작성 → 데이터 업데이트
         ↓
       CDC가 WAL 로그 읽기
         ↓
       Kafka에 발행
         ↓
검색 엔진 인덱서가 Elasticsearch에 인덱싱
```

**쿼리 모델**
- Elasticsearch에서 데이터 조회
- 필요 시 RDBMS에서도 데이터 조회 가능

<br><br>

### 2.3 점진적 도입을 위한 단계별 접근법

**1단계**
- 코드 단계에서 메서드 분리

**2단계**
- 반정규화 모델로 변경

**3단계**
- 저장소 분리 및 CDC 적용

**Kafka 사용 이유**
- 실패 시에도 리텐션이 길어 액션 리플레이 가능
- 복구 용이

<br><br>

### 2.4 실제 도입 시 고려사항

**CDC vs 직접 이벤트 발행**

| 방식 | 특징 | 장점 | 단점 |
|------|------|------|------|
| CDC (Debezium, DMS 등) | 테이블 단위 동기화 | 자동화된 변경 감지 | 원하지 않는 형태일 수 있음 |
| 직접 이벤트 발행 | 커스텀 이벤트 | 원하는 쿼리 데이터 전송 가능 | 개발 복잡도 증가 |

**주의사항**
- 읽기 작업에 적합
- 팀의 인프라 기술 수준 고려 필요
- CRUD 작업에 과도한 적용 피하기
- 동기화 문제 과소평가 금지
- 모니터링 필수

<br><br>

---

## 3. 이벤트 기반 아키텍처

### 3.1 동기화 방식 비교

#### 1) 동기식 모델 동기화
- DB 모델과 서버 컴포넌트가 2개 이상으로 분리
- 쿼리 모델 장애가 커맨드 모델 장애로 전파

<br>

#### 2) 비동기 모델 동기화 1
```
커맨드 모델 업데이트
    ↓
이벤트 큐에 이벤트 발행
    ↓
모델 동기화 컴포넌트가 구독
    ↓
쿼리 모델 업데이트
```

<br>

#### 3) 비동기 모델 동기화 2 (CDC 방식)
```
CDC가 변경 감지
    ↓
변경 전/후 데이터를 이벤트 큐에 발행
    ↓
모델 동기화
```

**특징**
- 테이블 단위 기준
- 쿼리 모델이 원하는 형태여야 함 (커스텀 필요)
- 모델 동기화 부분의 코드 복잡도 증가 가능

<br>

**아웃박스 패턴(Outbox Pattern)**
- 쿼리 모델을 손쉽게 업데이트 가능
- 하나의 모델 업데이트를 위해 여러 모델을 조합해야 하는 경우 유용
- 히스토리를 차곡차곡 쌓아 다른 곳에서도 재사용 가능
- ⚠️ 주의: 아웃박스 테이블 쓰기 비용 발생

<br><br>

#### 4) 비동기식 모델 동기화의 장점

**느슨한 결합**
- 커맨드 모델과 쿼리 모델 사이에 모델 동기화 컴포넌트 존재
- 직접 결합 방지

**장점**
- 이벤트 큐에 의한 장애 격리
- 이벤트 스트림 재사용 가능
- 다른 모델 초기화에 활용

**단점**
- 복잡한 오류 처리/재시도 메커니즘 필요
- 디버깅과 모니터링 난이도 상승

<br><br>

### 3.2 트랜잭션 관리

**서비스 레이어 트랜잭션**
- 서비스 레이어에서 트랜잭션이 걸려 있으면 DB 업데이트까지 트랜잭션 적용
- 아웃박스 테이블 업데이트와 커맨드 모델 업데이트를 함께 트랜잭션 처리하는 것이 일반적
- 비즈니스 가치에 따라 달라질 수 있음

**CDC 대안**
- 필요 없으면 생략 가능
- 애플리케이션에서 직접 폴링 방식으로 이벤트 관찰 구현 가능

<br><br>

### 3.3 이벤트 스키마 관리

#### 이벤트 스키마 포맷

**1) AVRO**
- Confluent Schema Registry가 Kafka와 자주 사용됨
- 생태계 최적화

**2) ProtoBuf**
- gRPC에 익숙한 경우 권장

<br><br>

#### 스키마 설계 및 버전 관리

**호환성 유지 원칙**

**후방 호환성**
1. 이벤트 삭제 또는 필수 필드 추가 시 쿼리 모델 수정 필요
2. 쿼리 모델이 이해할 수 없는 이벤트 처리 전략
    - Unknown Event 핸들러 구현 (Logging, Alert 포함)
    - 미처리 이벤트 큐 보관
    - 쿼리 모델 업데이트 후 재처리

**고려사항**
- 시간에 대한 기록이 남아 있어 모델 변경 시 이미 발행된 쿼리 모델도 업데이트 필요

#### 스키마 레지스트리

| 솔루션 | 라이선스 |
|--------|----------|
| Karapace | 무료 |
| Apicurio | 무료 |
| Confluent Schema Registry | 유료 |

<br><br>

---

## 4. Kafka 개념 및 실습

### 4.1 Kafka 동작 방식

```
1. 프로듀서가 이벤트 발행
2. 파티션에 이벤트(메시지) 저장
   - 같은 파티션 내 이벤트만 순서 보장
3. 파티션 레플리카로 가용성 확보
4. 파티션에 쌓인 이벤트가 순서대로 처리 및 전달
5. 파티션에서 복구 진행
6. 컨슈머들이 독립적으로 이벤트 소비
7. 각 컨슈머는 독립적인 offset 관리
8. 프로듀서가 파티션 결정
9. 컨슈머 리밸런싱으로 이벤트 재분배
10. 이벤트가 디스크에 반영구적으로 저장
```

<br>

### 4.2 Kafka 메시지 구조

**Key 섹션**
- 순서가 필요한 경우 비즈니스별로 담음
- 엔티티 ID 기반 파티셔닝

**Header 섹션**
- 이벤트의 메타데이터 전송

**Value 섹션**
- 비즈니스 데이터(바디 데이터)

<br>

### 4.3 파티션 관리

**파티션 불균형(Skew) 관리**
- 트래픽 집중 현상 방지
- 복합 키 사용 가능 (핫 키 + 유니크 키)

**순서 보장**
- 시간 순서 보장이 필요한 이벤트는 같은 파티션에 저장
- 파티셔너는 해싱을 통해 같은 키 값을 같은 파티션에 배치

<br>

### 4.4 컨슈머 그룹 관리

**기본 원리**
- 파티셔너는 컨슈머 그룹을 확인하지 않음
- 컨슈머 그룹별로 이벤트를 독립적으로 소비

**파티션과 컨슈머 수**
- 파티션이 3개, 컨슈머가 4개인 경우 → 1개의 컨슈머는 유휴 상태


<br>


### 4.5 오류 처리 및 모니터링

**실패한 이벤트 처리**
- 실패 메시지 무시 옵션
- Dead Letter Queue(DLQ)에 실패 메시지 수집 후 순차 처리

**멱등성의 중요성**
- 네트워크 등의 문제로 에러 발생 시 해당 오프셋부터 재처리
- 중복 처리되어도 결과가 동일하도록 보장
- 작업 완료 후 커밋되지 않은 오프셋도 멱등성으로 안전하게 처리

**모니터링**
- Kafka Admin에서 파티션별 오프셋 정보 확인
- 최신 모델과 현재 오프셋 차이로 지연 확인
- 커맨드 모델 변경 후 쿼리 모델 반영까지의 시간 측정

<br>

### 4.6 CDC 무중단 도입 전략

**문제 상황**
- 기존 서비스에 CDC를 무중단으로 도입
- 최초 1회 데이터 동기화 필요
- 운영 서비스는 중단 불가
- 전체 데이터 복사 중에도 쓰기 트래픽 발생

**해결 방안**
1. 기존 DB 풀스캔 시작
2. 변경/추가 이력은 CDC에 자동 기록
3. 풀스캔 완료 후 Kafka 동기화가 최신 오프셋부터 재스캔
4. 최신 오프셋 비교를 통해 동기화 완료 판단

**도구**
- Flinker를 활용한 병렬 읽기 및 적재


<br><br>

---

## 5. Debezium 프로젝트 실습

### 5.1 Docker Compose 설정

```yaml
# Kafka - 메시지 브로커
kafka:
  image: confluentinc/cp-kafka:7.9.0
  container_name: kafka
  depends_on:
    - zookeeper
  ports:
    - "9092:9092"
    - "29092:29092"
  volumes:
    - kafka_data:/var/lib/kafka/data
  environment:
    KAFKA_BROKER_ID: 1
    KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
    KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
    KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
    KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    # 토픽 자동 생성 설정
    KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
```


<br><br>

### 5.2 자동 토픽 생성 설정

**`KAFKA_AUTO_CREATE_TOPICS_ENABLE: true` 필요 이유**

Debezium은 CDC를 통해 데이터베이스 변경 사항을 Kafka 토픽으로 전송합니다.

**Debezium 커넥터가 자동 생성하는 토픽**
- `dbserver1.inventory.products` (각 테이블 단위 토픽)
- `dbserver1.inventory._schema` (스키마 메타데이터 저장용)
- `dbserver1.inventory._transaction` (트랜잭션 로그용)

**설정 미적용 시**
- `auto.create.topics.enable=false` 상태에서는 토픽이 존재하지 않아 오류 발생
- CDC가 시작되지 않음


<br><br>

### 5.3 Debezium 커넥터 설정

#### 테이블 포함 목록 설정

```json
"table.include.list": "public.products,public.product_prices,public.product_categories,public.product_tags,public.product_details,public.reviews,public.product_option_groups"
```

<br>

#### 메시지 키 매핑 설정

**ID 값 변환 처리**
- Debezium에서는 커넥터의 ID 값 변환을 수동으로 설정 필요
- `id` vs `productId` 호환성 문제 해결

```json
"message.key.columns": "public.products:id;public.product_prices:product_id;public.product_categories:product_id;public.product_tags:product_id;public.product_details:product_id;public.reviews:product_id;public.product_option_groups:product_id",

"transforms": "RenameProductKey,RouteByTable",

"transforms.RenameProductKey.type": "org.apache.kafka.connect.transforms.ReplaceField$Key",
"transforms.RenameProductKey.renames": "id:product_id",
"transforms.RenameProductKey.predicate": "isProducts",

"transforms.RouteByTable.type": "org.apache.kafka.connect.transforms.RegexRouter",
"transforms.RouteByTable.regex": "product.public.(.*)",
"transforms.RouteByTable.replacement": "product-events",

"predicates": "isProducts",
"predicates.isProducts.type": "org.apache.kafka.connect.transforms.predicates.TopicNameMatches",
"predicates.isProducts.pattern": ".*products$"
```

**AWS DMS 대안**
- AWS의 관리형 서비스인 AWS DMS 사용 시 ID 값 변환이 더 손쉽게 제공됨

<br><br>

#### 특수 케이스 처리

**ProductOption 테이블**
- ProductOptionGroup에만 productId 존재
- 직접적인 productId 참조 없음
- 스키마 변경하지 않는 경우 대비 필요

<br><br>

### 5.4 커넥터 등록 스크립트

```bash
# Product 커넥터 등록
curl -X POST -H "Content-Type: application/json" \
  --data @postgres-product-connector.json \
  http://localhost:8083/connectors

# Option/Image 커넥터 등록
curl -X POST -H "Content-Type: application/json" \
  --data @postgres-product-option-connector.json \
  http://localhost:8083/connectors

# Category 커넥터 등록
curl -X POST -H "Content-Type: application/json" \
  --data @postgres-category-connector.json \
  http://localhost:8083/connectors

# Brand 커넥터 등록
curl -X POST -H "Content-Type: application/json" \
  --data @postgres-brand-connector.json \
  http://localhost:8083/connectors

# Seller 커넥터 등록
curl -X POST -H "Content-Type: application/json" \
  --data @postgres-seller-connector.json \
  http://localhost:8083/connectors

# Tag 커넥터 등록
curl -X POST -H "Content-Type: application/json" \
  --data @postgres-tag-connector.json \
  http://localhost:8083/connectors
```

<br>

![treaning.png](/assets/images/cqrs/treaning.png)

<br><br>

### 5.5 토픽 이름 커스터마이징

```json
"transforms.RouteByTable.replacement": "product-events"
```

위 설정으로 모든 변경 이벤트를 `product-events` 토픽으로 라우팅할 수 있습니다.

<br>

![Pasted_Graphic_1.png](/assets/images/cqrs/Pasted_Graphic_1.png)

<br>

![Pasted_Graphic_2.png](/assets/images/cqrs/Pasted_Graphic_2.png)


<br><br>

### 5.6 Kafka UI에서 확인

**확인 방법**
1. Kafka UI의 라이브 모드에서 실시간 확인
2. 동일 파티션으로 전송 확인
3. 토픽에서 변경 내용 확인

---

## 참고사항

이 문서는 CQRS 강의 내용을 기반으로 작성되었으며, 실무 적용 시 프로젝트의 특성과 요구사항에 맞게 조정하여 사용해야 합니다.

### 주요 참고 자료
- Debezium 공식 문서
- Confluent Kafka 문서
- Elasticsearch 공식 문서
- AWS DMS 문서

---

<br><br>

## 6. 다중 데이터 저장소 전략

### 6.1 다중 데이터 저장소의 목적

**성능 최적화를 위한 전략**
- 같은 네트워크 내에서는 I/O 지연이 적음
- 각 DB의 특성에 맞는 데이터 저장

**조회 시간 기준**
- 전체 조회 시간: 150~200ms 이내 권장
- Elasticsearch + MongoDB + Redis 조합 활용

**사용 예시**
- 재고 데이터: Redis 캐싱으로 수십 ms 내 조회 가능
- 검색 필터링: Elasticsearch
- 원본 문서 조회: MongoDB

<br><br>

### 6.2 백엔드 개발 트렌드

**DB 선택 시 고려사항**
- DB의 자료구조 이해 필수
- 해당 DB 특성상 최적화 과정 파악
- 해결하고자 하는 문제에 적합한 오퍼레이션 확인

<br><br>

### 6.3 벡터 DB 고려사항

**Elasticsearch의 한계**
- 대량의 벡터 데이터 인덱싱 시 안정성 부족
- 벡터 기반 검색에는 전용 DB 사용 권장 (예: Qdrant)

**벡터 DB 특성**
- 차원 간 전환 시 부하 발생
- 성능 최적화가 중요

<br><br>

### 6.4 Elasticsearch vs MongoDB

#### Elasticsearch 특성

**작동 원리**
- 역색인(Inverted Index) 개념 사용
- 문서 ID를 여러 개 엮어서 조건에 맞는 연산 수행
- 결과 도출은 매우 빠름

**장단점**

| 작업 유형 | 속도 |
|----------|------|
| 필터링 및 검색 | 매우 빠름 ⚡ |
| 문서 ID 찾기 | 매우 빠름 ⚡ |
| 개별 문서 원본 조회 | 느림 🐢 |

<br>

**사용 권장 케이스**
- 초기 시스템에서 원본 데이터가 적은 경우
- 필터링이 주된 목적인 경우

<br><br>

#### MongoDB 특성

**작동 원리**
- B+Tree 구조
- 원본 문서를 찾는 속도가 매우 빠름

**장점**
- 개별 문서 조회 성능 우수
- 문서 지향 데이터베이스

<br><br>

### 6.5 I/O 최적화 전략

**네트워크 라운드 트립 고려**
- 데이터가 적은 경우: Elasticsearch 단일 조회 (1번의 라운드 트립)
- 데이터가 많은 경우: Elasticsearch + MongoDB 조합 (2번의 라운드 트립)

**결론**
- 비즈니스 특성에 맞는 다중 저장소 설계가 중요


<br><br>

---

## 7. 실습 코드 분석

### 7.1 모델 부분

**스키마 관리**
- `inStock`과 같은 비즈니스 필드 변경 시 스키마 업데이트
- 이벤트 스키마 무중단 교체 수행

<br>

**성능 최적화 원칙**
- ❌ 쿼리 시점에 계산 금지
- ✅ 커맨드 실행 시 계산하여 미리 DB에 저장

<br>

**필드 설계 예시**
- `inStock`: 재고 확인용 불린 필드
- 상세 수량 체크가 필요한 경우 별도 처리

<br>

**데이터 모델링 전략**
- Product와 직접 관련 있는 내용은 반정규화
- 참조 전략으로 JOIN 사용


<br><br>

### 7.2 비즈니스 및 서비스 부분

#### 주요 컴포넌트

**ProductDocumentOperations**
- MongoDB 문서 연산 처리

<br>

**QueryService**
- Elasticsearch와 MongoDB 검색 구현
- 캐싱 전략 적용

<br>

**캐싱 전략**
- 단일 검색 결과 캐싱
- `getProduct`와 같은 단일 객체 조회 시 캐싱


<br><br>

#### CDC 이벤트 처리

**cdcEvent 구조**
- `before`: 변경 전 데이터
- `after`: 변경 후 데이터
- `source`: 테이블 정보

<br>

#### 핸들러 구조

**Document 핸들러**
- MongoDB용 이벤트 핸들러 모음

**Search 핸들러**
- Elasticsearch용 이벤트 핸들러 모음
- SME (SearchModelEvent) 처리

**ProductSearchModelSyncer**
- 이벤트 핸들러 통합 관리
- 큐에서 이벤트 처리 가능 여부 체크
- 모델 업데이트 수행

<br><br>
 
### 7.3 디버깅 방법

**브레이크 포인트 활용**
- 개별 이벤트 처리 과정 파악
- 데이터 흐름 추적

**시스템 도식화**
- 손으로 직접 시스템 구조 그리기
- 참고 URL: https://app.excalidraw.com/l/zZ6L7Mz24A/8DJ2xINRMER

<br><br>

---

## 8. 실습 환경 구성

### 8.1 초기 서버 설정 순서

**권장 브랜치**
- 2번째 브랜치 사용 권장
- 브랜치 이동 시 설정 변경으로 에러 발생 가능
- 각 폴더에서 개별 클론 권장

<br>

**실행 순서**
1. DDL 파일 실행 (테이블 생성 및 데이터 INSERT)
    - docker-compose.yml에서 자동 실행 설정 가능
2. docker-compose.yml 실행
3. register.sh 실행 (Debezium CDC 커넥터 등록)
4. 톰캣 서버 시작
5. Kafka UI에서 이벤트 라이브 모드 확인 (선택)
6. API 테스트

<br>

**포트 정보**
- HTTP API: localhost:8080
- Kafka UI: localhost:8989

<br><br>

### 8.2 성능 특성

**병렬 처리 효과**
- INSERT 시 관련 테이블 개수만큼 이벤트 큐 생성
- 병렬 처리로 처리 시간 감소

<br>

**CQRS의 성능 이점**
- 조회 쿼리: 성능 향상 효과 제한적
- 상태 변경(INSERT, DELETE, UPDATE): 병렬 처리로 성능 향상
- DB를 요구사항에 따라 분리할 때 Kafka/CDC 필요

<br>

**아키텍처 원칙**

| 개념 | 설명 |
|------|------|
| CQRS | Command와 Query 책임 분리 |
| 이벤트 기반 아키텍처 | 비동기 이벤트 처리 |
| Polyglot Persistence | 다중 DB 전략 |
| CDC | 변경 데이터 캡처 |

<br>

![result_and_final.png](/assets/images/cqrs/result_and_final.png)


<br><br>

---

## 9. Kafka 개발 환경 이슈 해결

### 9.1 Cluster ID 불일치 에러

**에러 메시지**
```
Invalid cluster.id in: /var/lib/kafka/data/meta.properties
Expected E-G5GZXETG2XFSGwGaxGKQ, but read CX4OIZCKQ9-v0eXstX4ubA
```

<br>

**발생 원인**
1. Zookeeper에 등록된 Cluster ID: `E-G5GZXETG2XFSGwGaxGKQ`
2. Kafka 볼륨의 Cluster ID: `CX4OIZCKQ9-v0eXstX4ubA`
3. 두 ID가 불일치하여 Kafka가 시작 거부

<br>

**왜 발생하는가?**
- Kafka는 브로커 초기화 시 cluster.id 고정
- Zookeeper와 Kafka 데이터 디렉터리의 cluster.id 비교
- 불일치 시 데이터 보호를 위해 즉시 종료

<br><br>

### 9.2 해결 방안

#### 1️⃣ 로컬 개발 환경 (권장)

**데이터 완전 초기화**
```bash
# 컨테이너 중지
docker-compose down

# Kafka 데이터 볼륨 삭제
docker volume rm <kafka-volume-name>

# 바인드 마운트인 경우
rm -rf ./kafka-data

# 재실행
docker-compose up -d
```

<br>

#### 2️⃣ 데이터 보존이 필요한 경우

**확인 절차**
```bash
# Kafka 데이터 확인
cat /var/lib/kafka/data/meta.properties
# 출력: cluster.id=CX4OIZCKQ9-v0eXstX4ubA

# Zookeeper 확인
zookeeper-shell zookeeper:2181 get /cluster/id
```

**선택지**
- ✅ Zookeeper를 Kafka 데이터에 맞게 초기화
- ❌ Kafka 데이터에 수동으로 cluster.id 수정 (비권장)

<br>

#### 3️⃣ meta.properties 수동 수정 (비권장)

```bash
vi /var/lib/kafka/data/meta.properties
cluster.id=E-G5GZXETG2XFSGwGaxGKQ
```

⚠️ **주의**: 운영 환경에서는 절대 비권장

<br>

#### 4️⃣ 운영 환경 권장 아키텍처

```
[ Zookeeper (3 nodes) ]
        |
        |
[ Kafka Broker 1 ] — [ Kafka Broker 2 ] — [ Kafka Broker 3 ]
```

**볼륨 매핑**
```yaml
volumes:
  - /data/kafka/broker-1:/var/lib/kafka/data
```

- 운영에서는 docker volume ❌ / host bind mount ✅ 권장

<br>

#### 5️⃣ 안전한 Kafka 재기동 (Rolling Restart)

**올바른 절차**
1. Broker 1 중지
2. Broker 1 기동
3. ISR 정상 복귀 확인
4. Broker 2 반복
5. Broker 3 반복

**상태 확인**
```bash
kafka-topics.sh --bootstrap-server localhost:9092 --describe
# ISR에 모든 replica가 있어야 다음 브로커 진행
```

<br>

#### 6️⃣ Kafka 버전 업그레이드 전략

| 단계 | 설명 |
|------|------|
| 1 | 기존 브로커 중 1대 중지 |
| 2 | 새 이미지로 교체 |
| 3 | 동일 data 디렉터리로 기동 |
| 4 | 정상 join 확인 |
| 5 | 다음 브로커 진행 |

**절대 금지 사항**
- ❌ 기존 데이터 디렉터리에 다른 cluster.id Kafka 실행
- ❌ 전체 브로커 동시 종료

<br>

#### 7️⃣ Zookeeper 재구성 전략

**절대 금지**
- ❌ Zookeeper 전체 삭제
- ❌ Zookeeper 단일 노드 운영
- ❌ Kafka보다 먼저 삭제

**안전한 방식**
1. Zookeeper quorum 유지
2. Rolling restart
3. dataDir 유지

<br>

#### 8️⃣ KRaft 모드 (차세대 권장)

**장점**

| 항목 | ZK | KRaft |
|------|-----|-------|
| cluster.id | ZK 의존 | 자체 관리 |
| 구성 복잡도 | 높음 | 낮음 |
| 장애 포인트 | 많음 | 적음 |
| 운영 안정성 | 보통 | 높음 |

**운영 기준**
- Kafka 3.5+ → KRaft 적극 권장
- 신규 운영 환경이면 무조건 KRaft

<br><br>

### 9.3 분산 시스템 개발 방법론

#### 로컬 ↔ 운영 환경 이슈

**전형적인 시나리오**
```
① 로컬 A 컴퓨터
   - docker-compose up
   - Kafka + Zookeeper 실행
   - data 볼륨 생성 (cluster.id = A)

② docker-compose down
   - 컨테이너만 종료
   - 볼륨은 그대로 남음 (중요!)

③ 다른 컴퓨터 B
   - docker-compose.yml 수정
     (DB 추가, 네트워크 구조 변경 등)
   - git commit & push

④ 다시 로컬 A 컴퓨터
   - git pull
   - docker-compose up
   
👉 이 시점에서 에러 발생
```

<br>

#### Kafka 관점에서의 동작

| 단계 | Kafka 내부 동작 |
|------|----------------|
| 최초 실행 | Zookeeper에 cluster.id 등록 |
| Kafka data 볼륨 | meta.properties에 cluster.id 저장 |
| compose 변경 | 서비스 구조 재조정 |
| 재기동 | Zookeeper가 "새 클러스터"로 인식 |
| 결과 | 기존 Kafka 데이터 ≠ 현재 Zookeeper |

<br>

#### 가장 좋은 로컬 개발 전략

**docker-compose 예시**
```yaml
services:
  zookeeper:
    volumes:
      - zookeeper-data:/data

  kafka:
    volumes:
      - kafka-data:/var/lib/kafka/data

volumes:
  zookeeper-data:
  kafka-data:
```

**구조 변경 시**
```bash
docker-compose down -v
docker-compose up -d
```

<br>

#### 실무 워크플로우

**추천 루틴**
```bash
1. git pull
2. docker-compose down -v  # 중요!
3. docker-compose up -d
```


<br>

#### 상태 기반 분산 시스템의 공통 특성

| 시스템 | 동일 이슈 |
|--------|----------|
| Elasticsearch | cluster UUID mismatch |
| MongoDB ReplicaSet | replicaSetId mismatch |
| Redis Cluster | node-id conflict |
| etcd | member ID mismatch |

<br>

#### 정리

**로컬 개발**
```bash
git pull
docker-compose down -v
docker-compose up -d
```

<br>

**운영**
- 절대 `down -v` 금지
- Rolling restart만 허용
- 볼륨 수명 = 클러스터 수명

<br><br>

---

## 10. JPA 실무 가이드

### 10.1 JPA 연관관계 설정

#### 단방향 설정 권장

**기본 원칙**
- 웬만하면 JPA 단방향 설정 사용
- `@xToOne` 영속성 관계에서 LAZY 설정 기본
- 양방향 설정보다 단방향 설정 권장 (복잡성 감소)

**결론**
- 실무에서는 단방향 설정 우선
- 불가피한 경우에만 양방향 사용 및 신중한 관리

<br>

### 10.2 JPA FK 설정

**설정 위치**
- 주인이 아닌 자식 객체에서 FK 설정

**단방향 CASCADE 설정**
```java
@ManyToOne(fetch = FetchType.LAZY)
@OnDelete(action = OnDeleteAction.CASCADE)
@JoinColumn(name = "product_id")
private Product product;

@ManyToOne(fetch = FetchType.LAZY)
@OnDelete(action = OnDeleteAction.CASCADE)
@JoinColumn(name = "tag_id")
private Tag tag;
```

<br>

### 10.3 IntelliJ Ultimate 기능

**JPA Entity 자동 생성**
1. DB 연결
2. 테이블 우클릭
3. `Create JPA Entities From DB` 선택

**Entity Attributes 추가**
- `Create JPA Entities Attributes From DB`
- 추가된 칼럼이나 FK 칼럼 자동 생성

<br>

### 10.4 Fetch Join

#### 수정 전 (N+1 문제)

```java
private List<ProductLineEntity> getProductLineEntitiesByCategory(
    Long categoryId, Pageable pageable, String keyword) {
    
    List<OrderSpecifier<?>> orderSpecifiers = getOrderSpecifiers(pageable.getSort());
    
    // ProductLine 3개 조회 시 Product 쿼리도 3번 추가 실행
    return jpaQueryFactory
        .selectDistinct(qProductLine)
        .from(qProductLine)
        .where(qProductLine.category.categoryId.eq(categoryId)
            .and(qProductLine.deletedAt.isNull())
            .and(getSearchCondition(keyword)))
        .orderBy(orderSpecifiers.toArray(new OrderSpecifier[0]))
        .offset(pageable.getOffset())
        .limit(pageable.getPageSize() + 1)
        .fetch();
}
```

**문제점**
- ProductLine 조회: 1개 쿼리
- 각 ProductLine의 Product 조회: N개 쿼리
- 총 1 + N개 쿼리 실행

<br>

#### 수정 후 (Fetch Join 적용)

```java
private List<ProductLineEntity> getProductLineEntitiesByCategory(
    Long categoryId, Pageable pageable, String keyword) {
    
    List<OrderSpecifier<?>> orderSpecifiers = getOrderSpecifiers(pageable.getSort());
    
    return jpaQueryFactory
        .selectDistinct(qProductLine)
        .from(qProductLine)
        .leftJoin(qProductLine.products, qProduct).fetchJoin()
        .where(qProductLine.category.categoryId.eq(categoryId)
            .and(qProductLine.deletedAt.isNull())
            .and(getSearchCondition(keyword)))
        .orderBy(orderSpecifiers.toArray(new OrderSpecifier[0]))
        .offset(pageable.getOffset())
        .limit(pageable.getPageSize() + 1)
        .fetch();
}
```

**개선점**
- 쿼리 4개 → 1개로 감소
- ProductLine과 Product를 한 번에 조회

<br><br>

### 10.5 Fetch Join 사용 시 문제점

#### A. 메모리 문제

**증상**
- SQL LIMIT 구문 미적용
- `firstResult/maxResults`가 메모리 내에서 적용됨
- ⚠️ 경고: 컬렉션 페치와 페이지네이션 동시 사용

**원인: Hibernate의 컬렉션 페치 페이지네이션**
- OneToMany, ManyToMany 관계는 조인 시 데이터 수 변경
- 메모리 내에서 페이지네이션 적용
- 대용량 데이터 처리 시 성능 문제

**예시**
```
ProductLine 3개 × 각각 Comment 7개 = 21개 DB Row
→ 모든 데이터를 메모리로 가져와 JPA가 페이지네이션 계산
→ OutOfMemoryError 발생 가능
```

<br>

#### B. 응답 시간 문제

**성능 저하**
- 해당 카테고리의 전체 ProductLine과 Product를 메모리에 로드
- 약 100만 건 데이터 기준: 35~40초 소요
- 사용자 입장에서는 서버 다운으로 인식

<br>

#### C. 2개 이상의 1:N 관계 Fetch Join 불가

**MultipleBagFetchException**
- 2개 이상의 1:N 관계 컬렉션 Fetch Join 시 발생
- 카테시안 곱(Cartesian Product)으로 데이터 급증
- JPA에서 의도적으로 차단

**Trade-off**
- N+1 쿼리 + DB 커넥션 증가
- vs
- N+1 해결 + DB 커넥션 감소

<br>

#### D. 해결 방안: Batch Size 설정

**글로벌 설정**
```yaml
spring:
  jpa:
    properties:
      hibernate:
        default_batch_fetch_size: 1000
```

**효과**
- N+1 문제 해결
- 메모리 문제 방지
- 페이지네이션 정상 작동

<br>

### 10.6 Projection 활용

**생성자 방식**
- DTO에 쿼리 파라미터와 동일한 생성자 필요
- `@RequestParam` 없이 DTO로 파라미터 수신 가능

<br>

### 10.7 JPAQuery 분리

**Content vs Count**
```java
// Content 조회
JPAQuery<Entity> contentQuery = ...
List<Entity> content = contentQuery.fetch();

// Count 조회
JPAQuery<Long> countQuery = ...
Long total = countQuery.fetchOne();
```

**N+1 문제 해결**
- `default_batch_fetch_size` 글로벌 설정 필수

<br>

### 10.8 Page 인터페이스 사용

**PageImpl 활용**
```java
return new PageImpl<>(content, pageable, total);
```

<br><br>
---

## 11. 종합 정리

### 11.1 CQRS 핵심 요약

**주요 개념**
1. Command와 Query 책임 분리
2. 각 모델에 최적화된 DB 선택
3. 이벤트 기반 비동기 동기화

**성능 최적화**
- 읽기 부하 감소: 100 → 90
- 쓰기 작업 병렬 처리
- 다중 DB 전략으로 특화된 성능

<br>

### 11.2 실무 적용 체크리스트

**기술 스택**
- [ ] Kafka / Zookeeper (또는 KRaft)
- [ ] Debezium (CDC)
- [ ] Elasticsearch (검색/필터링)
- [ ] MongoDB (문서 저장)
- [ ] Redis (캐싱)
- [ ] PostgreSQL (커맨드 모델)

**개발 환경**
- [ ] Docker Compose 설정
- [ ] 로컬 개발 워크플로우 정립
- [ ] 모니터링 도구 구성

**코드 품질**
- [ ] JPA N+1 문제 해결
- [ ] Batch Size 설정
- [ ] 단방향 연관관계 우선
- [ ] Fetch Join 신중하게 사용

<br>

### 11.3 운영 고려사항

**모니터링**
- Kafka 오프셋 지연 확인
- 쿼리 모델 동기화 시간 측정
- 응답 시간 목표: 100~200ms

**장애 대응**
- 이벤트 큐에 의한 장애 격리
- Dead Letter Queue 구성
- 멱등성 보장

**확장성**
- 파티션 전략 수립
- 컨슈머 그룹 관리
- Rolling Restart 절차